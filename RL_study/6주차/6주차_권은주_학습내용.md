# 5강 Model Free Control
## On-Policy Monte-Carlo Control
- Generalised Policy Iteration
  - Policy evaluation -> Iterative policy evaluation
  - Policy improvement -> Greedy policy improvement
- model-free -> MDP X
  - value-function
    - policy evaluation은 가능
    - policy improvement는 불가능
  - q-funtion은 둘 다 가능 but, greedy하게 만 선택 -> e-greedy 방법 이용
  - 
## On-Policy Temporal-Difference Learning
- Sarsa
  - policy evaluation에 사용
  - 한 step으로 Q를 업데이트하는 극단적인 방법
- n-step sarsa
- Forward View Sarsa
- Backward View Sarsa
##### -> 한 번 action을 하면 모든 칸을 다 업데이트하는 방법

## Off-Policy Learning
- feature
  - 경험 쌓는 policy와 학습하는 policy가 다름
  - 옛날에 했던 경험, 다른 Agent가 했던 경험 사용 가능
  - 효율적으로 경험을 이용하는 방법
  - 탐험적인 행동을하며 optimal한 값을 찾을 수 있음
- importance sampling
- Q-learning


