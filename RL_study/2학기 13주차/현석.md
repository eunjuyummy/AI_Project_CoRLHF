# 실험 방법: 목표 지표 및 개입 확률/비율 설정
### 에이전트가 달성해야 할 누적 보상의 목표 값을 설정 Ex) 2000, 2500, 3000개입 확률 (intervention_probabilities):
각 목표 지표에 도달했을 때 적용할 개입 확률을 설정 (목표 지표를 달성할수록 개입 확률을 낮추어 에이전트의 자율성을 점진적으로 높임)
액션 비율 (intervention_ratios):
	개입 시 전문가 액션과 정책 액션의 조합 비율을 설정 
	목표 지표를 달성할수록 전문가 액션의 비율을 낮추어 에이전트의 자율성을 높임
현재 목표 지표 인덱스 및 초기 개입 확률/비율 설정:
	current_target_index는 현재 달성해야 할 목표 지표의 인덱스를 추적
	current_intervene_prob와 current_ratio는 현재 목표 지표에 따라 개입 확률과 액션 비율을 설정

![image](https://github.com/user-attachments/assets/9dd5b6d6-3d77-49b8-a314-1f9895bb8647)

# 실험 방법: 개입여부 결정
정책 Q 값(policy_q)이 기준 Q 값(gt_q)의 특정 비율(intervene_threshold) 이하일 때 개입 여부를 결정
intervention_probabilities에 따라 개입 여부를 확률적으로 결정
동적 조정: 목표 지표를 달성함에 따라 current_intervene_prob이 변경되어 개입 확률이 조정
액션 결정:
	개입 시: 전문가 액션과 정책 액션을 설정된 비율(current_ratio)에 따라 조합하여 최종 액션을 결정
	개입하지 않을 시: 정책 액션을 그대로 사용
![image](https://github.com/user-attachments/assets/2aa3d550-d0f1-404d-a0b7-b4ecbebf4f7c)
# 실험 결과
### 오히려 기존보다 낮은 sample efficiency를 보여줌
개입확률을 높이는 것은 기존 보다 낮은 탐색 자유도이기에 결과 또한 낮게 나온것으로 추정
![image](https://github.com/user-attachments/assets/1cf25b9c-3d63-43db-8c40-63c5ffcb6c8a)

